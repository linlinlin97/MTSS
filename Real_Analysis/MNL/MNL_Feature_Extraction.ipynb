{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "from scipy.linalg import svd\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.special import gamma as g\n",
    "from scipy.optimize import minimize\n",
    "from _util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanvar_meanprex(mean, var):\n",
    "    \"mean-variance to precision\"\n",
    "    return 1/(mean*(1-mean)/var-1)\n",
    "\n",
    "def logistic(x):\n",
    "    return np.exp(x) / (np.exp(x) + 1)\n",
    "def logit(x):\n",
    "    return np.log(x/(1-x))\n",
    "def likelhood_beta(psi,a,b):\n",
    "    out = np.log(g(psi)/(g(b*psi)*g((1-b)*psi)))+(b*psi-1)*np.log(a)+((1-b)*psi-1)*np.log(1-a)\n",
    "    return -np.sum(out)\n",
    "from fancyimpute import MatrixFactorization\n",
    "\n",
    "#########################\n",
    "def v_2_y(mat):\n",
    "    temp = 2 / (1+mat) - 1\n",
    "    return logit(temp)\n",
    "\n",
    "def v_2_theta(v):\n",
    "    return 1/(1+v)\n",
    "def y_2_theta(y):\n",
    "    return (logistic(y)+1)/2\n",
    "def theta_2_v(theta):\n",
    "    return 1/theta - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Beta_loglike(y_mean, v_obs, phi_beta):\n",
    "    alphas, betas = beta_reparameterize(y_2_theta(y_mean),phi_beta)\n",
    "    from scipy.stats import beta\n",
    "    theta_obs = v_2_theta(v_obs)\n",
    "    return sum([np.log(beta.pdf(y, a, b)) for y, a, b in zip(theta_obs, alphas, betas)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('MNL_real_dataset/ratings.dat', sep='::', names = [\"user_id\",\"movie_id\",\"rating\",\"timestamp\"]  , encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal \n",
    "* Approach I: get feature and utility from real data, but do not assume relationship between them (though we need to be careful when get featurrs)\n",
    "    1. apply low-rank matrix completion and SVD to extract the feature of each movie as $x_i$, from the training dataset. \n",
    "    2. estimate the utility of each movie as $v_i$, from the testing dataset\n",
    "    3. simulate customer's choice with an MNL model parameterized by $\\{v_i\\}$. Some algorithms might additionally use $\\{x_i\\}$ if they believe it helps.\n",
    "* Approach II: get feature and theta from real data, and simulate following our model\n",
    "\n",
    "1. Impute only training, get features from the continuous rating + [d, X_transform, with_intercept]\n",
    "2. Impute All, then binarize, get features from traiing, and predict the testing + d = 5, [X_transform, with_intercept]\n",
    "    1. try d = 5 to impute but d = 3 as feature\n",
    "\n",
    "1. What we need: a good but not perfect relationship between x and v.\n",
    "\n",
    "## Our model\n",
    "* $\\theta_i \\sim Beta(\\frac{logistic(x_i^T \\gamma)+ 1}{2}, \\psi)$\n",
    "* $E(\\theta_i|x_i) = \\frac{logistic(x_i^T \\gamma)+ 1}{2}$\n",
    "* $\\theta_i = (1+v_i)^{-1}$\n",
    "* $logit(2E(\\theta_i|x_i)-1) = x_i^T \\gamma$\n",
    "* $logit(p) = log(p/(1-p))$\n",
    "* $logit(2E((1+v_i)^{-1}|x_i)-1) = x_i^T \\gamma$\n",
    "* though not rigrous, we can probably follow this to transform the entry\n",
    "\n",
    "## SVD\n",
    "* When we use SVD to extract the features $x_i$ and then use mean ratings as $v_i$, we assume $E(v_i|x_i) = x_i^T \\gamma$, which is not fair to us (when we design feature in real datasets, we also would like to make sure our model is close to being correct)\n",
    "    * but we can still have a reasonable model even with this? r2 says so. \n",
    "    * If we go with approach II, regression here is just a check\n",
    "\n",
    "## Else\n",
    "* v \\in [0,1]; various way to normalize and define v\n",
    "* larger variations (but feature should be accurate)\n",
    "* Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=1000\n",
    "selected_movies = list(data.movie_id.value_counts().index[:L])\n",
    "selected_users = list(data[data.movie_id.isin(selected_movies)].user_id.value_counts().index[:])\n",
    "selected_data=data[data.movie_id.isin(selected_movies)][data.user_id.isin(selected_users)]\n",
    "len(selected_data)\n",
    "selected_movies = [a-1 for a in selected_movies]\n",
    "selected_users = [a-1 for a in selected_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 6040\n",
    "num_movies = 3952\n",
    "#W_feedback_matrix = np.zeros((num_users, num_movies))\n",
    "W_feedback_ratings = np.empty((num_users, num_movies))\n",
    "W_feedback_ratings[:] = np.nan\n",
    "W_feedback_ratings[np.array(data.user_id-1), np.array(data.movie_id-1)] = np.array(data.rating/5)\n",
    "# W_feedback_ratings[np.array(data.user_id-1), np.array(data.movie_id-1)] = np.array(data.rating > 3).astype(int)\n",
    "# randomly permuting the users\n",
    "random.shuffle(selected_users)\n",
    "W_feedback_ratings = W_feedback_ratings[selected_users,:]\n",
    "W_feedback_ratings = W_feedback_ratings[:,selected_movies]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be updated, if needed\n",
    "# something wrong here!!!\n",
    "W_train = W_feedback_ratings[:num_movies//2,:]\n",
    "W_test = W_feedback_ratings[num_movies//2:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_best_gamma_phi(p, X, v):\n",
    "    \"\"\" suppose we can see all v w/o error and in hindsight, find the best phi, gamma; for debug purpose\"\"\"\n",
    "    import pymc3 as pm\n",
    "    n_init = 2000\n",
    "    n_tune = 200\n",
    "    chains = 1\n",
    "    n_sample = 2000\n",
    "\n",
    "    with pm.Model() as Normal_Geom:\n",
    "        gamma_temp = pm.MvNormal('gamma', mu=np.zeros(p), cov=np.identity(p),shape=p)\n",
    "        phi = pm.Beta('phi', alpha= 1, beta=1, shape=1)\n",
    "        alpha_temp = pm.math.dot(X, gamma_temp)\n",
    "        mean_theta = (logistic(alpha_temp)+1)/2\n",
    "        alpha_Beta, beta_Beta = beta_reparameterize(mean_theta, phi)\n",
    "        theta = v_2_theta(v)\n",
    "        theta = pm.Beta('theta', alpha= alpha_Beta, beta=beta_Beta, shape=L, observed = theta)\n",
    "        trace = pm.sample(n_sample, tune = n_tune, chains = chains\n",
    "                          , cores = 1, progressbar = 1, init='adapt_diag',\n",
    "                          target_accept=0.95, trace = None);\n",
    "    return {'gamma' : np.mean(trace[\"gamma\"], 0), 'phi' : np.mean(trace[\"phi\"], 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 1000)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_feedback_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features (from Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute\n",
    "for d in [5, 10]:\n",
    "     W_train_softimpute = MatrixFactorization(rank=d,\n",
    "        learning_rate=0.05,\n",
    "             max_iters=50,\n",
    "             shrinkage_value=0,\n",
    "             min_value=None,\n",
    "             max_value=None,\n",
    "             verbose=True).fit_transform(W_feedback_ratings)\n",
    "    dump(W_train_softimpute, 'MNL_real_dataset/W_train_softimpute_back_{}'.format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train_softimpute = load('MNL_real_dataset/W_train_softimpute_back_{}'.format(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the regression's quality (on Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNL utility estimates\n",
    "W_train_mean = np.nanmean(W_train, axis = 0) \n",
    "W_test_mean = np.nanmean(W_test, axis = 0) \n",
    "W_train_binary_mean = np.nanmean(W_train >= 0.8, axis = 0) \n",
    "W_test_binary_mean = np.nanmean(W_test >= 0.8, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = W_test_mean\n",
    "y = v_2_y(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_transform in ['l2']:\n",
    "    for with_intercept in [1]:\n",
    "        for d in [5]:\n",
    "            W_train_softimpute = load('MNL_real_dataset/W_train_softimpute_back_{}'.format(d))\n",
    "            U, s, VT = svd(W_train_softimpute)\n",
    "            X = movie_features = np.matmul(VT.T[:,:d],np.diag(s[:d]))\n",
    "            X = preprocessing.normalize(X, norm='l2') \n",
    "\n",
    "            if with_intercept:\n",
    "                X = sm.add_constant(X)\n",
    "            results = fit_best_gamma_phi(X.shape[1], X, v)\n",
    "            gamma = results['gamma']\n",
    "            best_phi = results['phi'][0]\n",
    "            y_mean = X.dot(gamma)\n",
    "            v_y_mean = theta_2_v(y_2_theta(y_mean))\n",
    "            v_y = theta_2_v(y_2_theta(y))\n",
    "\n",
    "            print(\"fitting R2 = {:.2f}\".format(r2_score(y, y_mean)))\n",
    "            print(\"fitting R2 for v = {:.2f}\".format(r2_score(v_y_mean, v_y)))\n",
    "\n",
    "            n_train = 750\n",
    "            results2 = fit_best_gamma_phi(X.shape[1], X[:n_train], v[:n_train]) \n",
    "            y1 = y[n_train:]\n",
    "            y2 = X[n_train:].dot(results2['gamma'])\n",
    "            print(\"prediction R2 = {:.2f}\".format(r2_score(y1, y2)))\n",
    "            v1 = theta_2_v(y_2_theta(y1))\n",
    "            v2 = theta_2_v(y_2_theta(y2))\n",
    "            print(\"prediction R2 for v = {:.2f}\".format(r2_score(v1, v2)))\n",
    "\n",
    "            print('max_para = {:.2f}'.format(max(abs(gamma))))\n",
    "            print('best_phi = {:.2f}'.format(best_phi))\n",
    "\n",
    "            out = {\n",
    "                   'W_test_mean': W_test_mean,\n",
    "                   'movie_features':X,\n",
    "                   'true_gamma_wrt_test': gamma,\n",
    "                   'true_phi_wrt_test': best_phi,\n",
    "            }\n",
    "\n",
    "            fp = 'MNL_real_dataset/MNL_realdata_d_{}_X_transform_{}_with_intercept_{}'.format(d, X_transform, with_intercept)\n",
    "            dump(out, fp)    \n",
    "            print(\"\\n\")\n",
    "            # _binary\n",
    "        print(\"*\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.7.9)",
   "language": "python",
   "name": "py379"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
